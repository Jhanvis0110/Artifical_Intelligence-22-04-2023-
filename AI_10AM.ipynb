{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLfONm0cE/lDtVOM5OAnVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhanvis0110/Artifical_Intelligence-22-04-2023-/blob/main/AI_10AM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM8GkLrmT-EY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=tf.constant([1,2,3,4,5,6])   # constant is used for no change in future. it is a method function.\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IGjffoWUNvb",
        "outputId": "de61138f-c635-4055-8155-51d5f87bffee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.Variable([1,2,3,4,5,6])   #Variable is used to make change in future. it is a class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTVFxffIU_D8",
        "outputId": "6055f8d0-4945-4768-9094-bac4feedc7ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(6,) dtype=int32, numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant([1,2,3,4,5,6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6ydU-8YU_Aj",
        "outputId": "6a4bd390-958b-4b63-de6f-67efa5c7b7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "fwNlbb-pU--B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=np.array([1,2,3,4,5,6])"
      ],
      "metadata": {
        "id": "m1-5c5LPU-7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a+c   # array + array --> broadcasting.(if shape of arrays are same)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXgjk-iBU-4v",
        "outputId": "67536cea-8ab8-4c92-d8ff-c4f5f1e68e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([ 2,  4,  6,  8, 10, 12], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d=np.array([7,8,9,0,9])"
      ],
      "metadata": {
        "id": "jRg6WkNLU-z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c+d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "9GcoIkop0QLr",
        "outputId": "671896c3-0d4f-46d7-d49a-33dd2a1c421c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ad687b5fa348>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,) (5,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e=np.array([1,2,3,4,5],dtype=np.str_)"
      ],
      "metadata": {
        "id": "S4mYdg-EaVif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e"
      ],
      "metadata": {
        "id": "jy40uzWTaVu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f=np.array([7,8,9,0,8],dtype=np.str_)"
      ],
      "metadata": {
        "id": "77fnujzNaVxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpJhNSeiaVz6",
        "outputId": "e152893b-02ac-4c05-ea9e-63c814833a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['7', '8', '9', '0', '8'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g=np.array([1,2,3,4,5],dtype=np.int8)"
      ],
      "metadata": {
        "id": "CixPk-p2aV2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h=np.array([7,8,9,0,8],dtype=np.float64)"
      ],
      "metadata": {
        "id": "JyBB1ImVaV51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "g+h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXKdbhGUdyan",
        "outputId": "9cc00c5e-2474-4bcb-a528-3b89f8c7497c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8., 10., 12.,  4., 13.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=tf.Variable([1,2,3,4,5,6])  # variable is mutable ie can be changed."
      ],
      "metadata": {
        "id": "tMHmtiMRdydY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xl-zzVcdyf3",
        "outputId": "5d4918bd-1e6c-4185-d391-a62d56a721f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140279473529296"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i.assign_add([1,2,3,4,5,6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpafjpJWdyjK",
        "outputId": "ec8b9584-9af8-43b2-ba17-52e35ec91994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(6,) dtype=int32, numpy=array([ 2,  4,  6,  8, 10, 12], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAsv86I5dymA",
        "outputId": "409a7f46-ee98-44bf-e26b-7742029d6c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(6,) dtype=int32, numpy=array([ 2,  4,  6,  8, 10, 12], dtype=int32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uUDHO01esAb",
        "outputId": "705055eb-9db7-4563-e9c2-2be2a5e678e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140279473529296"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "j=tf.constant([1,2,3,4,5,6])"
      ],
      "metadata": {
        "id": "yiqo8IdResED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(id(j))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj5bGfDiesHQ",
        "outputId": "0e7aa932-6d34-42bc-bffa-673180f6729f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140279474281760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i+j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBCDRooXesLT",
        "outputId": "fd04133f-8e30-4969-f4af-71d9ed545d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([ 3,  6,  9, 12, 15, 18], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library for deep learning.\n",
        "\n",
        "> tesorflow by google --> 2015 tensorflow v1, it provide an api by keras, 2019 v2\n",
        "\n",
        "> pytorch by facebook\n",
        "\n",
        "> cntk by microsoft."
      ],
      "metadata": {
        "id": "hEsLuJFwh9zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jXfFpBRl0_AN",
        "outputId": "290afd2e-eec9-43ce-868b-1a37f7a77e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ANN --> Artifical Neural Network"
      ],
      "metadata": {
        "id": "3qyQIwimiFYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "hMhqIaWohyaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4bRJfvN1Haw",
        "outputId": "ca75e204-2526-402c-d5d7-eabf9366680e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[[[ 59,  62,  63],\n",
              "           [ 43,  46,  45],\n",
              "           [ 50,  48,  43],\n",
              "           ...,\n",
              "           [158, 132, 108],\n",
              "           [152, 125, 102],\n",
              "           [148, 124, 103]],\n",
              "  \n",
              "          [[ 16,  20,  20],\n",
              "           [  0,   0,   0],\n",
              "           [ 18,   8,   0],\n",
              "           ...,\n",
              "           [123,  88,  55],\n",
              "           [119,  83,  50],\n",
              "           [122,  87,  57]],\n",
              "  \n",
              "          [[ 25,  24,  21],\n",
              "           [ 16,   7,   0],\n",
              "           [ 49,  27,   8],\n",
              "           ...,\n",
              "           [118,  84,  50],\n",
              "           [120,  84,  50],\n",
              "           [109,  73,  42]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[208, 170,  96],\n",
              "           [201, 153,  34],\n",
              "           [198, 161,  26],\n",
              "           ...,\n",
              "           [160, 133,  70],\n",
              "           [ 56,  31,   7],\n",
              "           [ 53,  34,  20]],\n",
              "  \n",
              "          [[180, 139,  96],\n",
              "           [173, 123,  42],\n",
              "           [186, 144,  30],\n",
              "           ...,\n",
              "           [184, 148,  94],\n",
              "           [ 97,  62,  34],\n",
              "           [ 83,  53,  34]],\n",
              "  \n",
              "          [[177, 144, 116],\n",
              "           [168, 129,  94],\n",
              "           [179, 142,  87],\n",
              "           ...,\n",
              "           [216, 184, 140],\n",
              "           [151, 118,  84],\n",
              "           [123,  92,  72]]],\n",
              "  \n",
              "  \n",
              "         [[[154, 177, 187],\n",
              "           [126, 137, 136],\n",
              "           [105, 104,  95],\n",
              "           ...,\n",
              "           [ 91,  95,  71],\n",
              "           [ 87,  90,  71],\n",
              "           [ 79,  81,  70]],\n",
              "  \n",
              "          [[140, 160, 169],\n",
              "           [145, 153, 154],\n",
              "           [125, 125, 118],\n",
              "           ...,\n",
              "           [ 96,  99,  78],\n",
              "           [ 77,  80,  62],\n",
              "           [ 71,  73,  61]],\n",
              "  \n",
              "          [[140, 155, 164],\n",
              "           [139, 146, 149],\n",
              "           [115, 115, 112],\n",
              "           ...,\n",
              "           [ 79,  82,  64],\n",
              "           [ 68,  70,  55],\n",
              "           [ 67,  69,  55]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[175, 167, 166],\n",
              "           [156, 154, 160],\n",
              "           [154, 160, 170],\n",
              "           ...,\n",
              "           [ 42,  34,  36],\n",
              "           [ 61,  53,  57],\n",
              "           [ 93,  83,  91]],\n",
              "  \n",
              "          [[165, 154, 128],\n",
              "           [156, 152, 130],\n",
              "           [159, 161, 142],\n",
              "           ...,\n",
              "           [103,  93,  96],\n",
              "           [123, 114, 120],\n",
              "           [131, 121, 131]],\n",
              "  \n",
              "          [[163, 148, 120],\n",
              "           [158, 148, 122],\n",
              "           [163, 156, 133],\n",
              "           ...,\n",
              "           [143, 133, 139],\n",
              "           [143, 134, 142],\n",
              "           [143, 133, 144]]],\n",
              "  \n",
              "  \n",
              "         [[[255, 255, 255],\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253],\n",
              "           ...,\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253]],\n",
              "  \n",
              "          [[255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           ...,\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255]],\n",
              "  \n",
              "          [[255, 255, 255],\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254],\n",
              "           ...,\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[113, 120, 112],\n",
              "           [111, 118, 111],\n",
              "           [105, 112, 106],\n",
              "           ...,\n",
              "           [ 72,  81,  80],\n",
              "           [ 72,  80,  79],\n",
              "           [ 72,  80,  79]],\n",
              "  \n",
              "          [[111, 118, 110],\n",
              "           [104, 111, 104],\n",
              "           [ 99, 106,  98],\n",
              "           ...,\n",
              "           [ 68,  75,  73],\n",
              "           [ 70,  76,  75],\n",
              "           [ 78,  84,  82]],\n",
              "  \n",
              "          [[106, 113, 105],\n",
              "           [ 99, 106,  98],\n",
              "           [ 95, 102,  94],\n",
              "           ...,\n",
              "           [ 78,  85,  83],\n",
              "           [ 79,  85,  83],\n",
              "           [ 80,  86,  84]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[ 35, 178, 235],\n",
              "           [ 40, 176, 239],\n",
              "           [ 42, 176, 241],\n",
              "           ...,\n",
              "           [ 99, 177, 219],\n",
              "           [ 79, 147, 197],\n",
              "           [ 89, 148, 189]],\n",
              "  \n",
              "          [[ 57, 182, 234],\n",
              "           [ 44, 184, 250],\n",
              "           [ 50, 183, 240],\n",
              "           ...,\n",
              "           [156, 182, 200],\n",
              "           [141, 177, 206],\n",
              "           [116, 149, 175]],\n",
              "  \n",
              "          [[ 98, 197, 237],\n",
              "           [ 64, 189, 252],\n",
              "           [ 69, 192, 245],\n",
              "           ...,\n",
              "           [188, 195, 206],\n",
              "           [119, 135, 147],\n",
              "           [ 61,  79,  90]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 73,  79,  77],\n",
              "           [ 53,  63,  68],\n",
              "           [ 54,  68,  80],\n",
              "           ...,\n",
              "           [ 17,  40,  64],\n",
              "           [ 21,  36,  51],\n",
              "           [ 33,  48,  49]],\n",
              "  \n",
              "          [[ 61,  68,  75],\n",
              "           [ 55,  70,  86],\n",
              "           [ 57,  79, 103],\n",
              "           ...,\n",
              "           [ 24,  48,  72],\n",
              "           [ 17,  35,  53],\n",
              "           [  7,  23,  32]],\n",
              "  \n",
              "          [[ 44,  56,  73],\n",
              "           [ 46,  66,  88],\n",
              "           [ 49,  77, 105],\n",
              "           ...,\n",
              "           [ 27,  52,  77],\n",
              "           [ 21,  43,  66],\n",
              "           [ 12,  31,  50]]],\n",
              "  \n",
              "  \n",
              "         [[[189, 211, 240],\n",
              "           [186, 208, 236],\n",
              "           [185, 207, 235],\n",
              "           ...,\n",
              "           [175, 195, 224],\n",
              "           [172, 194, 222],\n",
              "           [169, 194, 220]],\n",
              "  \n",
              "          [[194, 210, 239],\n",
              "           [191, 207, 236],\n",
              "           [190, 206, 235],\n",
              "           ...,\n",
              "           [173, 192, 220],\n",
              "           [171, 191, 218],\n",
              "           [167, 190, 216]],\n",
              "  \n",
              "          [[208, 219, 244],\n",
              "           [205, 216, 240],\n",
              "           [204, 215, 239],\n",
              "           ...,\n",
              "           [175, 191, 217],\n",
              "           [172, 190, 216],\n",
              "           [169, 191, 215]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[207, 199, 181],\n",
              "           [203, 195, 175],\n",
              "           [203, 196, 173],\n",
              "           ...,\n",
              "           [135, 132, 127],\n",
              "           [162, 158, 150],\n",
              "           [168, 163, 151]],\n",
              "  \n",
              "          [[198, 190, 170],\n",
              "           [189, 181, 159],\n",
              "           [180, 172, 147],\n",
              "           ...,\n",
              "           [178, 171, 160],\n",
              "           [175, 169, 156],\n",
              "           [175, 169, 154]],\n",
              "  \n",
              "          [[198, 189, 173],\n",
              "           [189, 181, 162],\n",
              "           [178, 170, 149],\n",
              "           ...,\n",
              "           [195, 184, 169],\n",
              "           [196, 189, 171],\n",
              "           [195, 190, 171]]],\n",
              "  \n",
              "  \n",
              "         [[[229, 229, 239],\n",
              "           [236, 237, 247],\n",
              "           [234, 236, 247],\n",
              "           ...,\n",
              "           [217, 219, 233],\n",
              "           [221, 223, 234],\n",
              "           [222, 223, 233]],\n",
              "  \n",
              "          [[222, 221, 229],\n",
              "           [239, 239, 249],\n",
              "           [233, 234, 246],\n",
              "           ...,\n",
              "           [223, 223, 236],\n",
              "           [227, 228, 238],\n",
              "           [210, 211, 220]],\n",
              "  \n",
              "          [[213, 206, 211],\n",
              "           [234, 232, 239],\n",
              "           [231, 233, 244],\n",
              "           ...,\n",
              "           [220, 220, 232],\n",
              "           [220, 219, 232],\n",
              "           [202, 203, 215]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[150, 143, 135],\n",
              "           [140, 135, 127],\n",
              "           [132, 127, 120],\n",
              "           ...,\n",
              "           [224, 222, 218],\n",
              "           [230, 228, 225],\n",
              "           [241, 241, 238]],\n",
              "  \n",
              "          [[137, 132, 126],\n",
              "           [130, 127, 120],\n",
              "           [125, 121, 115],\n",
              "           ...,\n",
              "           [181, 180, 178],\n",
              "           [202, 201, 198],\n",
              "           [212, 211, 207]],\n",
              "  \n",
              "          [[122, 119, 114],\n",
              "           [118, 116, 110],\n",
              "           [120, 116, 111],\n",
              "           ...,\n",
              "           [179, 177, 173],\n",
              "           [164, 164, 162],\n",
              "           [163, 163, 161]]]], dtype=uint8),\n",
              "  array([[6],\n",
              "         [9],\n",
              "         [9],\n",
              "         ...,\n",
              "         [9],\n",
              "         [1],\n",
              "         [1]], dtype=uint8)),\n",
              " (array([[[[158, 112,  49],\n",
              "           [159, 111,  47],\n",
              "           [165, 116,  51],\n",
              "           ...,\n",
              "           [137,  95,  36],\n",
              "           [126,  91,  36],\n",
              "           [116,  85,  33]],\n",
              "  \n",
              "          [[152, 112,  51],\n",
              "           [151, 110,  40],\n",
              "           [159, 114,  45],\n",
              "           ...,\n",
              "           [136,  95,  31],\n",
              "           [125,  91,  32],\n",
              "           [119,  88,  34]],\n",
              "  \n",
              "          [[151, 110,  47],\n",
              "           [151, 109,  33],\n",
              "           [158, 111,  36],\n",
              "           ...,\n",
              "           [139,  98,  34],\n",
              "           [130,  95,  34],\n",
              "           [120,  89,  33]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 68, 124, 177],\n",
              "           [ 42, 100, 148],\n",
              "           [ 31,  88, 137],\n",
              "           ...,\n",
              "           [ 38,  97, 146],\n",
              "           [ 13,  64, 108],\n",
              "           [ 40,  85, 127]],\n",
              "  \n",
              "          [[ 61, 116, 168],\n",
              "           [ 49, 102, 148],\n",
              "           [ 35,  85, 132],\n",
              "           ...,\n",
              "           [ 26,  82, 130],\n",
              "           [ 29,  82, 126],\n",
              "           [ 20,  64, 107]],\n",
              "  \n",
              "          [[ 54, 107, 160],\n",
              "           [ 56, 105, 149],\n",
              "           [ 45,  89, 132],\n",
              "           ...,\n",
              "           [ 24,  77, 124],\n",
              "           [ 34,  84, 129],\n",
              "           [ 21,  67, 110]]],\n",
              "  \n",
              "  \n",
              "         [[[235, 235, 235],\n",
              "           [231, 231, 231],\n",
              "           [232, 232, 232],\n",
              "           ...,\n",
              "           [233, 233, 233],\n",
              "           [233, 233, 233],\n",
              "           [232, 232, 232]],\n",
              "  \n",
              "          [[238, 238, 238],\n",
              "           [235, 235, 235],\n",
              "           [235, 235, 235],\n",
              "           ...,\n",
              "           [236, 236, 236],\n",
              "           [236, 236, 236],\n",
              "           [235, 235, 235]],\n",
              "  \n",
              "          [[237, 237, 237],\n",
              "           [234, 234, 234],\n",
              "           [234, 234, 234],\n",
              "           ...,\n",
              "           [235, 235, 235],\n",
              "           [235, 235, 235],\n",
              "           [234, 234, 234]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 87,  99,  89],\n",
              "           [ 43,  51,  37],\n",
              "           [ 19,  23,  11],\n",
              "           ...,\n",
              "           [169, 184, 179],\n",
              "           [182, 197, 193],\n",
              "           [188, 202, 201]],\n",
              "  \n",
              "          [[ 82,  96,  82],\n",
              "           [ 46,  57,  36],\n",
              "           [ 36,  44,  22],\n",
              "           ...,\n",
              "           [174, 189, 183],\n",
              "           [185, 200, 196],\n",
              "           [187, 202, 200]],\n",
              "  \n",
              "          [[ 85, 101,  83],\n",
              "           [ 62,  75,  48],\n",
              "           [ 58,  67,  38],\n",
              "           ...,\n",
              "           [168, 183, 178],\n",
              "           [180, 195, 191],\n",
              "           [186, 200, 199]]],\n",
              "  \n",
              "  \n",
              "         [[[158, 190, 222],\n",
              "           [158, 187, 218],\n",
              "           [139, 166, 194],\n",
              "           ...,\n",
              "           [228, 231, 234],\n",
              "           [237, 239, 243],\n",
              "           [238, 241, 246]],\n",
              "  \n",
              "          [[170, 200, 229],\n",
              "           [172, 199, 226],\n",
              "           [151, 176, 201],\n",
              "           ...,\n",
              "           [232, 232, 236],\n",
              "           [246, 246, 250],\n",
              "           [246, 247, 251]],\n",
              "  \n",
              "          [[174, 201, 225],\n",
              "           [176, 200, 222],\n",
              "           [157, 179, 199],\n",
              "           ...,\n",
              "           [230, 229, 232],\n",
              "           [250, 249, 251],\n",
              "           [245, 244, 247]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 31,  40,  45],\n",
              "           [ 30,  39,  44],\n",
              "           [ 26,  35,  40],\n",
              "           ...,\n",
              "           [ 37,  40,  46],\n",
              "           [  9,  13,  14],\n",
              "           [  4,   7,   5]],\n",
              "  \n",
              "          [[ 23,  34,  39],\n",
              "           [ 27,  38,  43],\n",
              "           [ 25,  36,  41],\n",
              "           ...,\n",
              "           [ 19,  20,  24],\n",
              "           [  4,   6,   3],\n",
              "           [  5,   7,   3]],\n",
              "  \n",
              "          [[ 28,  41,  47],\n",
              "           [ 30,  43,  50],\n",
              "           [ 32,  45,  52],\n",
              "           ...,\n",
              "           [  5,   6,   8],\n",
              "           [  4,   5,   3],\n",
              "           [  7,   8,   7]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[ 20,  15,  12],\n",
              "           [ 19,  14,  11],\n",
              "           [ 15,  14,  11],\n",
              "           ...,\n",
              "           [ 10,   9,   7],\n",
              "           [ 12,  11,   9],\n",
              "           [ 13,  12,  10]],\n",
              "  \n",
              "          [[ 21,  16,  13],\n",
              "           [ 20,  16,  13],\n",
              "           [ 18,  17,  12],\n",
              "           ...,\n",
              "           [ 10,   9,   7],\n",
              "           [ 10,   9,   7],\n",
              "           [ 12,  11,   9]],\n",
              "  \n",
              "          [[ 21,  16,  13],\n",
              "           [ 21,  17,  12],\n",
              "           [ 20,  18,  11],\n",
              "           ...,\n",
              "           [ 12,  11,   9],\n",
              "           [ 12,  11,   9],\n",
              "           [ 13,  12,  10]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 33,  25,  13],\n",
              "           [ 34,  26,  15],\n",
              "           [ 34,  26,  15],\n",
              "           ...,\n",
              "           [ 28,  25,  52],\n",
              "           [ 29,  25,  58],\n",
              "           [ 23,  20,  42]],\n",
              "  \n",
              "          [[ 33,  25,  14],\n",
              "           [ 34,  26,  15],\n",
              "           [ 34,  26,  15],\n",
              "           ...,\n",
              "           [ 27,  24,  52],\n",
              "           [ 27,  24,  56],\n",
              "           [ 25,  22,  47]],\n",
              "  \n",
              "          [[ 31,  23,  12],\n",
              "           [ 32,  24,  13],\n",
              "           [ 33,  25,  14],\n",
              "           ...,\n",
              "           [ 24,  23,  50],\n",
              "           [ 26,  23,  53],\n",
              "           [ 25,  20,  47]]],\n",
              "  \n",
              "  \n",
              "         [[[ 25,  40,  12],\n",
              "           [ 15,  36,   3],\n",
              "           [ 23,  41,  18],\n",
              "           ...,\n",
              "           [ 61,  82,  78],\n",
              "           [ 92, 113, 112],\n",
              "           [ 75,  89,  92]],\n",
              "  \n",
              "          [[ 12,  25,   6],\n",
              "           [ 20,  37,   7],\n",
              "           [ 24,  36,  15],\n",
              "           ...,\n",
              "           [115, 134, 138],\n",
              "           [149, 168, 177],\n",
              "           [104, 117, 131]],\n",
              "  \n",
              "          [[ 12,  25,  11],\n",
              "           [ 15,  29,   6],\n",
              "           [ 34,  40,  24],\n",
              "           ...,\n",
              "           [154, 172, 182],\n",
              "           [157, 175, 192],\n",
              "           [116, 129, 151]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[100, 129,  81],\n",
              "           [103, 132,  84],\n",
              "           [104, 134,  86],\n",
              "           ...,\n",
              "           [ 97, 128,  84],\n",
              "           [ 98, 126,  84],\n",
              "           [ 91, 121,  79]],\n",
              "  \n",
              "          [[103, 132,  83],\n",
              "           [104, 131,  83],\n",
              "           [107, 135,  87],\n",
              "           ...,\n",
              "           [101, 132,  87],\n",
              "           [ 99, 127,  84],\n",
              "           [ 92, 121,  79]],\n",
              "  \n",
              "          [[ 95, 126,  78],\n",
              "           [ 95, 123,  76],\n",
              "           [101, 128,  81],\n",
              "           ...,\n",
              "           [ 93, 124,  80],\n",
              "           [ 95, 123,  81],\n",
              "           [ 92, 120,  80]]],\n",
              "  \n",
              "  \n",
              "         [[[ 73,  78,  75],\n",
              "           [ 98, 103, 113],\n",
              "           [ 99, 106, 114],\n",
              "           ...,\n",
              "           [135, 150, 152],\n",
              "           [135, 149, 154],\n",
              "           [203, 215, 223]],\n",
              "  \n",
              "          [[ 69,  73,  70],\n",
              "           [ 84,  89,  97],\n",
              "           [ 68,  75,  81],\n",
              "           ...,\n",
              "           [ 85,  95,  89],\n",
              "           [ 71,  82,  80],\n",
              "           [120, 133, 135]],\n",
              "  \n",
              "          [[ 69,  73,  70],\n",
              "           [ 90,  95, 100],\n",
              "           [ 62,  71,  74],\n",
              "           ...,\n",
              "           [ 74,  81,  70],\n",
              "           [ 53,  62,  54],\n",
              "           [ 62,  74,  69]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[123, 128,  96],\n",
              "           [132, 132, 102],\n",
              "           [129, 128, 100],\n",
              "           ...,\n",
              "           [108, 107,  88],\n",
              "           [ 62,  60,  55],\n",
              "           [ 27,  27,  28]],\n",
              "  \n",
              "          [[115, 121,  91],\n",
              "           [123, 124,  95],\n",
              "           [129, 126,  99],\n",
              "           ...,\n",
              "           [115, 116,  94],\n",
              "           [ 66,  65,  59],\n",
              "           [ 27,  27,  27]],\n",
              "  \n",
              "          [[116, 120,  90],\n",
              "           [121, 122,  94],\n",
              "           [129, 128, 101],\n",
              "           ...,\n",
              "           [116, 115,  94],\n",
              "           [ 68,  65,  58],\n",
              "           [ 27,  26,  26]]]], dtype=uint8),\n",
              "  array([[3],\n",
              "         [8],\n",
              "         [8],\n",
              "         ...,\n",
              "         [5],\n",
              "         [1],\n",
              "         [7]], dtype=uint8)))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test)=tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "JxFaCV-u1WnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0c2b6b-aea7-4975-f8d9-eb2ce0fdaacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcPWUeVOhyhg",
        "outputId": "8f7b595d-ae9d-4263-8cb8-c753cdf2cb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LPcBr8p0ksbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "8DF1ihJ-ksLI",
        "outputId": "038c2e1c-f5b9-4449-ac10-aa21f0931c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f95592c4400>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "xB4C8Tr-ksAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(X_train[0])\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "41TC51ARkrvb",
        "outputId": "d24a7a4a-1aba-43aa-a602-e4f35c1e2505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9533F34B80>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for i in range(5):\n",
        "  cv2_imshow(X_train[i])\n",
        "  print()\n",
        "  cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "Ulj4kpVgmJtu",
        "outputId": "a546687e-0807-474c-e194-7e31318488e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9533F356C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9533F34B80>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9533F356C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nGNgGArA+YU6AwMDAwMTAwMDg10gqqTpGQaEpEMQihyTohwjgndnMYqk9L9FSDqZUE2dw3AbIaknjirJz7AbIenFiSInrsjwFCGpznAVWbJH/NZnCIuFgYGBgeE0XIbPI8aNofkDsqQQAwODPpOzDFs00/eTP1nOQlUyMjAwTEv/8IiBQY/xz7drJ88cfPlEkI0BoTProRUDA8OjjddOMDAwMKSJ3mPACVb+64QxmbBIb8AnyYBHklEVj+R/JjySDJb4jMVj5/b/OB1IJQAAg3ksR3QPgSAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9533F34B80>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGPyg5u9/e1xyCV9+/7WDMJkwJOXZcRvq8ub3ZXkO7HI2T37/jsOlcfbfv3txyYn8/f3aCYecwtm/v+twacz4/XcHPw65gA+/D4rjMvTv37/zcRk6/ffv3+o45Azu/v69BpfGV79/H+HBJfn39+9IXHLz///9K4/Lxid/v/fgCHAGh99/76CLYcYnNskbx/ApoyoAAGeYO0QsY6cRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9533F353C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nN3QPwtBYRQG8EMU0e0uZLIw+QKXRZlMGC0GX8CglE0pk0VxPwQmE5YrJYPVIjYMlImSwXNiMOi97319AM/6O6fzh+g/Y5hr5mrRNByseAZba4D7EnlSN8wy3uAYXJOwDEw0ohKwD9mtxehqRLQBCnZr8GPkJ/Ll79y0m37GiIjiK2AQsGMYiIbryyvjmZO20U9gAIcjTg43GhfethOROToO+En6xRUlZhnSjd+I6BY7xVIRY79w4XapR9IOSTWWYSWUqE0xlH771R7UrULefm5U2pxVCt0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "y_train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7vOuGLxnBIj",
        "outputId": "b77a8850-3caf-4ea0-9a64-3afa8cba41b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEQBBYd8nyAo",
        "outputId": "f7fbb4b5-3f97-446f-d3d0-a9e5bfd8df12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVLuJGnUnyGN",
        "outputId": "25260048-d9ba-4038-c00a-7097ce240c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jp-RT-onyL-",
        "outputId": "0dfc365b-f047-415f-df06-5d54e02f10e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE5mOxtJnyRC",
        "outputId": "f1646527-dd3c-428b-aa13-403d12022759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "Model= tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),     # Input Layer\n",
        "    tf.keras.layers.Dense(1000,activation='relu'),    # Hidden Layer\n",
        "    tf.keras.layers.Dense(100,activation='relu'),     # Hidden Layer\n",
        "    tf.keras.layers.Dense(10,activation='sigmoid')    # Output Layer\n",
        "])\n",
        "Model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])\n",
        "Model.fit(X_train,y_train,epochs=10)      # echos is the itration."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG6C0AK9oaap",
        "outputId": "8e15b146-eedb-41a7-8ee5-ef7e11a887c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 35s 18ms/step - loss: 1.2369 - accuracy: 0.8054\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 33s 18ms/step - loss: 0.3408 - accuracy: 0.9182\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.1951 - accuracy: 0.9494\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1645 - accuracy: 0.9579\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.1387 - accuracy: 0.9653\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1159 - accuracy: 0.9713\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.1087 - accuracy: 0.9740\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0977 - accuracy: 0.9772\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.1015 - accuracy: 0.9767\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0842 - accuracy: 0.9799\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9533ec19f0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "metadata": {
        "id": "icai95GmobFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=load_iris()"
      ],
      "metadata": {
        "id": "4xGLE-DdZ-Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " X=data.data # feature\n"
      ],
      "metadata": {
        "id": "6OqBnkteobBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=data.target     # target\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I42SeBooa9N",
        "outputId": "5a23e7ec-ccb3-4556-e2f8-0c479cb2b99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Neural Network\n",
        "Model2=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4,activation='sigmoid'), #input layer=4 -- no. of features\n",
        "    tf.keras.layers.Dense(3,activation='softmax') #output_layer--> class=3 ie iris_setosa,virigina,vesti\n",
        "])\n",
        "Model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "               metrics=['accuracy'])  # Adam is most powerful optimizer\n",
        "\n",
        "Model2.fit(X,y,batch_size=10,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYrOLLtdZsYW",
        "outputId": "4e3ce029-841c-4254-94a5-22e46992fcfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 2ms/step - loss: 1.2564 - accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.2405 - accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.2255 - accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.2108 - accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.1972 - accuracy: 0.3333\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.1836 - accuracy: 0.3333\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.1704 - accuracy: 0.3333\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.1575 - accuracy: 0.3333\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.1452 - accuracy: 0.3333\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.1329 - accuracy: 0.3333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f952c873f70>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model2=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    tf.keras.layers.Dense(100,activation='relu'),\n",
        "    tf.keras.layers.Dense(3,activation='softmax')\n",
        "])\n",
        "Model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "Model2.fit(X,y,batch_size=10,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T8AinT4cbeY",
        "outputId": "bde1e3e4-3c52-4e44-b079-e9410e8ed9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 2ms/step - loss: 1.0541 - accuracy: 0.6667\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.9576 - accuracy: 0.6667\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.8771 - accuracy: 0.6667\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.8034 - accuracy: 0.6667\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7316 - accuracy: 0.6667\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.6800\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.6667\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.8200\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7867\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7267\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f952c7aba00>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sc=MinMaxScaler()\n",
        "X_sc=sc.fit_transform(X)\n",
        "X_sc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG3DlKfzcbaV",
        "outputId": "3fc50c55-8952-4158-8b79-4c8b321199eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
              "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
              "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
              "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
              "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
              "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
              "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
              "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
              "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
              "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
              "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
              "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
              "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
              "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
              "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
              "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
              "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
              "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
              "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
              "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
              "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
              "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
              "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
              "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
              "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
              "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
              "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
              "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
              "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
              "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
              "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
              "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
              "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
              "       [0.16666667, 0.45833333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
              "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
              "       [0.16666667, 0.66666667, 0.06779661, 0.        ],\n",
              "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
              "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
              "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
              "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
              "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
              "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
              "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
              "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
              "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
              "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
              "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
              "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
              "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
              "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
              "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
              "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
              "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
              "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
              "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
              "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
              "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
              "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
              "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
              "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
              "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
              "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
              "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
              "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
              "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
              "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
              "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
              "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
              "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
              "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
              "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
              "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
              "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
              "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
              "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
              "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
              "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
              "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
              "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
              "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
              "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
              "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
              "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
              "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
              "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
              "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
              "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
              "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
              "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
              "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
              "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
              "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
              "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
              "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
              "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
              "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
              "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
              "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
              "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
              "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
              "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
              "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
              "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
              "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
              "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
              "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
              "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
              "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
              "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
              "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
              "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
              "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
              "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
              "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
              "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
              "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
              "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
              "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
              "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
              "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
              "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
              "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
              "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
              "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
              "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
              "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
              "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
              "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
              "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
              "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
              "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
              "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
              "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
              "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
              "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
              "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
              "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
              "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
              "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
              "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
              "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
              "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
              "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
              "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
              "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
              "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
              "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)    # for fixing data.\n",
        "\n",
        "Model2=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    tf.keras.layers.Dense(100,activation='relu'),\n",
        "    tf.keras.layers.Dense(50,activation='relu'),\n",
        "    tf.keras.layers.Dense(20,activation='tanh'),\n",
        "    tf.keras.layers.Dense(10,activation='tanh'),\n",
        "\n",
        "    tf.keras.layers.Dense(3,activation='softmax')\n",
        "])\n",
        "Model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "Model2.fit(X_sc,y,batch_size=10,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvyYPCAQcbUk",
        "outputId": "65b72e4e-4a62-4afc-d99b-ae4cfd498da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 1.0761 - accuracy: 0.3533\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.9880 - accuracy: 0.6333\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.8351 - accuracy: 0.6667\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6667\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7067\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8800\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.9600\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.9267\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 0.9400\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9467\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f952ef3b010>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(41)\n",
        "\n",
        "Model2=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    tf.keras.layers.Dense(100,activation='relu'),\n",
        "    tf.keras.layers.Dense(50,activation='relu'),\n",
        "    tf.keras.layers.Dense(20,activation='tanh'),\n",
        "    tf.keras.layers.Dense(10,activation='tanh'),\n",
        "\n",
        "    tf.keras.layers.Dense(3,activation='softmax')\n",
        "])\n",
        "Model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "               loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "Model2.fit(X_sc,y,batch_size=10,epochs=10)"
      ],
      "metadata": {
        "id": "7NKaJczBcbO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cf2d1a-e877-480d-9f17-ad94d6ea588f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 2s 5ms/step - loss: 1.1055 - accuracy: 0.3800\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.5733\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.6333\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.6800\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7467\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8333\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8067\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.8867\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.7067\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.6133\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f952f45b5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "ce8dMnfxcbKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb53b21-0e83-4df0-f2d8-0b4d8e9191eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "WIfdfwNZcbD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a943f3e6-1a52-43e1-932f-16b85d8fa6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "id": "1jeuhmq_oSJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a0556e-236a-4ef7-809d-d08f1f8736a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(X_train[0])"
      ],
      "metadata": {
        "id": "RaANOjTqofXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "664f39bb-5d5e-4359-cd1c-fba06c1bf72e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9530732470>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.ndarray.flatten(X_train[0])"
      ],
      "metadata": {
        "id": "ZE06gPeCot6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b8030c-ed37-4915-fa7d-ee6ba0ae93b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
              "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
              "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
              "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
              "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
              "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
              "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
              "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
              "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
              "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "date: 30-04-2023\n"
      ],
      "metadata": {
        "id": "pac5CfOZuYmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "data=load_iris()\n",
        "X=data[\"data\"]\n",
        "y=data[\"target\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_iris,X_test_iris,y_train_iris,y_test_iris=train_test_split(X,y,random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "_M7rl1wd12aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "Model2=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    tf.keras.layers.Dense(8,activation='tanh'),\n",
        "    tf.keras.layers.Dense(5,activation='tanh'),\n",
        "    tf.keras.layers.Dense(3,activation='softmax')\n",
        "])\n",
        "Model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "Model2.fit(X_sc,y,batch_size=10,epochs=10)  #X_train_iris,y_train_iris"
      ],
      "metadata": {
        "id": "U5DYr3c4otj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b98d01-489e-4111-cb84-dd91ceae0e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 1s 2ms/step - loss: 1.1139 - accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.0897 - accuracy: 0.3733\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.0686 - accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.0517 - accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.0334 - accuracy: 0.3467\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.0142 - accuracy: 0.3600\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.3733\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.9689 - accuracy: 0.4400\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.9420 - accuracy: 0.5867\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.9121 - accuracy: 0.6600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9532e29c60>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "Model2=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    tf.keras.layers.Dense(8,activation='tanh'),\n",
        "    tf.keras.layers.Dense(5,activation='tanh'),\n",
        "    tf.keras.layers.Dense(3,activation='softmax')\n",
        "])\n",
        "Model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "               metrics=['accuracy','mae','mse'])\n",
        "\n",
        "Model2.fit( X_train_iris,y_train_iris,batch_size=10,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ortZJ7deWr-2",
        "outputId": "156c9840-61a9-41c5-c256-55c1c10559d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 1.1137 - accuracy: 0.5625 - mae: 0.9018 - mse: 1.1350\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0501 - accuracy: 0.6518 - mae: 0.9018 - mse: 1.1370\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9990 - accuracy: 0.6518 - mae: 0.9018 - mse: 1.1402\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9546 - accuracy: 0.6518 - mae: 0.9018 - mse: 1.1441\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9157 - accuracy: 0.6518 - mae: 0.9018 - mse: 1.1482\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8803 - accuracy: 0.6518 - mae: 0.9018 - mse: 1.1517\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8481 - accuracy: 0.6518 - mae: 0.9018 - mse: 1.1534\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8162 - accuracy: 0.6518 - mae: 0.9018 - mse: 1.1556\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7883 - accuracy: 0.6518 - mae: 0.9018 - mse: 1.1595\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7623 - accuracy: 0.6518 - mae: 0.9018 - mse: 1.1631\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f95328d18d0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "Model2=tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4,activation='relu'),\n",
        "    tf.keras.layers.Dense(8,activation='tanh'),\n",
        "    tf.keras.layers.Dense(5,activation='tanh'),\n",
        "    tf.keras.layers.Dense(3,activation='softmax')\n",
        "])\n",
        "Model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               loss=tf.keras.losses.mean_absolute_error,\n",
        "               metrics=['accuracy','mae','mse'])\n",
        "\n",
        "Model2.fit( X_train_iris,y_train_iris,batch_size=10,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8_gXl-Ubfn7",
        "outputId": "5923024d-d17f-4ff4-cc59-41dd6aa932fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 1s 3ms/step - loss: 0.9018 - accuracy: 0.3036 - mae: 0.9018 - mse: 1.1409\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.3036 - mae: 0.9018 - mse: 1.1409\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9018 - accuracy: 0.3036 - mae: 0.9018 - mse: 1.1409\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.3036 - mae: 0.9018 - mse: 1.1409\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9018 - accuracy: 0.3036 - mae: 0.9018 - mse: 1.1409\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.3036 - mae: 0.9018 - mse: 1.1409\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.3036 - mae: 0.9018 - mse: 1.1409\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.3036 - mae: 0.9018 - mse: 1.1409\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.3036 - mae: 0.9018 - mse: 1.1410\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.3036 - mae: 0.9018 - mse: 1.1410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f953349a020>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample=[[1.2,3.4,5.6,2]]\n",
        "result=Model2.predict(sample)\n",
        "import numpy as np\n",
        "\n",
        "np.argmax(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20ZEWBeHTSTR",
        "outputId": "db48d761-bc7c-4d63-b182-c41816d6505f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 115ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=['setosa','versicolor','verginica']"
      ],
      "metadata": {
        "id": "iZgAcitxbBJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if result==classes[0]:\n",
        "  print(\"setosa\")\n",
        "elif result==classes[1]:\n",
        "  print(\"versicolor\")\n",
        "else:\n",
        "  print(\"verginica\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIJdcymsTg0B",
        "outputId": "6d77dd3d-edd9-4810-dc4a-b1e3c8053206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verginica\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-2fa840e5eee9>:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if result==classes[0]:\n",
            "<ipython-input-61-2fa840e5eee9>:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  elif result==classes[1]:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Losses:\n",
        "> MAE\n",
        "\n",
        "> MSE\n",
        "\n",
        "> RMSE\n",
        "\n",
        "> OLS(Ordinary List Square Error)\n",
        "\n",
        ">Categorical_crossentropy\n",
        "\n",
        "> Sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "KXXcMWw9wXqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sparse_categorical_crossentropy: if target not in form of one hot endcoded then i will use it.\n",
        "\n",
        "categorical_crossentropy: if target is in one hot encoded form then use categorical_crossentropy.\n",
        "\n",
        "Scaling is import in deep learning while training the model."
      ],
      "metadata": {
        "id": "Gb6TLRwPwS_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN: Convolutional Neural Network"
      ],
      "metadata": {
        "id": "1zCYz5dFwVWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "w3ODEV9iumZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test)=tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "0gX-ZIcByDtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "mBIXJQoJyDqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "TEEWvbNWyDnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "_Prq-EYQyDj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "id": "DiuBHciKyDgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]/255   # scaling data as 255 is max range of broadcasting"
      ],
      "metadata": {
        "id": "FJWEkb_ezfHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# without padding in image \"valid\"\n",
        "\n",
        "cnn=tf.keras.Sequential([\n",
        "\n",
        "    # cnn layer\n",
        "    tf.keras.layers.Conv2D(32,(3,3),strides=(1,1),padding='valid',input_shape=(28,28,1),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),strides=(1,1),padding='valid',input_shape=(28,28,1),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "\n",
        "    # ann layers connected after cnn layers.\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100,activation='relu'),\n",
        "    tf.keras.layers.Dense(25,activation='relu'),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "cnn.fit( X_train/255,y_train,batch_size=32,epochs=10)"
      ],
      "metadata": {
        "id": "Dyg5BsrgzfEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with padding in image \"same\"\n",
        "\n",
        "cnn=tf.keras.Sequential([\n",
        "\n",
        "    # cnn layer\n",
        "    tf.keras.layers.Conv2D(32,(3,3),strides=(2,2),padding='same',input_shape=(28,28,1),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),strides=(2,2),padding='same',input_shape=(28,28,1),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "\n",
        "    # ann layers connected after cnn layers.\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(100,activation='relu'),\n",
        "    tf.keras.layers.Dense(25,activation='relu'),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "cnn.fit( X_train/255,y_train,batch_size=32,epochs=10)"
      ],
      "metadata": {
        "id": "UMFjfFjZdfA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cjVxm-lzde9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C1f2zB0Ade5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XFZ2Mq3PzfBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8om4nsHze-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ffQ_UHIdze8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00LjLw3bze4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3_vNE3_azevW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0auao7-hct7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XlJrzgb8hcqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "46iur_QehcnP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}